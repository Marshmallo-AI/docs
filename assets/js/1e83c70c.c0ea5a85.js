"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[635],{4577(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"features/learning","title":"Learning","description":"Learning turns reward rationales into stable, reusable guidance for the agent.","source":"@site/docs/features/learning.md","sourceDirName":"features","slug":"/features/learning","permalink":"/features/learning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/features/learning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Rewards","permalink":"/features/rewards"},"next":{"title":"Simulation","permalink":"/features/simulation"}}');var a=r(4848),i=r(8453);const t={sidebar_position:3},o="Learning",d={},l=[{value:"Inputs To Learning",id:"inputs-to-learning",level:2},{value:"What A Learning Is",id:"what-a-learning-is",level:2},{value:"Shadow vs Active",id:"shadow-vs-active",level:2},{value:"How We Know A Learning Works",id:"how-we-know-a-learning-works",level:2},{value:"Where Learnings Live",id:"where-learnings-live",level:2},{value:"How Learnings Are Used",id:"how-learnings-are-used",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"learning",children:"Learning"})}),"\n",(0,a.jsxs)(n.p,{children:["Learning turns reward rationales into stable, reusable guidance for the agent.\nThe goal is simple: ",(0,a.jsx)(n.strong,{children:"reduce failures and keep decisions consistent"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"inputs-to-learning",children:"Inputs To Learning"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsx)(n.p,{children:"Learning runs after rewards. It uses:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"task reward output (score + rationale + principles)"}),"\n",(0,a.jsx)(n.li,{children:"task trajectory context (same task the judge saw)"}),"\n",(0,a.jsx)(n.li,{children:"agent definition (system prompt and tools)"}),"\n"]}),(0,a.jsx)(n.p,{children:"Learning never runs on guesses. It only uses what was actually captured."})]}),"\n",(0,a.jsx)(n.h2,{id:"what-a-learning-is",children:"What A Learning Is"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsx)(n.p,{children:"Each learning is stored as a small, structured rule:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"cue"}),": what to detect in the task or context"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"action"}),": what the agent should do"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"expected effect"}),": why this helps"]}),"\n"]}),(0,a.jsx)(n.p,{children:"This format makes learnings easy to apply and to measure."})]}),"\n",(0,a.jsx)(n.h2,{id:"shadow-vs-active",children:"Shadow vs Active"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsxs)(n.p,{children:["Learnings start in ",(0,a.jsx)(n.strong,{children:"shadow"}),":"]}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"they are tracked"}),"\n",(0,a.jsx)(n.li,{children:"they are not injected into the prompt"}),"\n"]}),(0,a.jsxs)(n.p,{children:["When a learning proves useful over time, it moves to ",(0,a.jsx)(n.strong,{children:"active"}),":"]}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"it is injected into the prompt"}),"\n",(0,a.jsx)(n.li,{children:"its adoption and outcomes are tracked"}),"\n"]}),(0,a.jsx)(n.p,{children:"If it harms performance, it can be demoted back to shadow."})]}),"\n",(0,a.jsx)(n.h2,{id:"how-we-know-a-learning-works",children:"How We Know A Learning Works"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsx)(n.p,{children:"Marlo tracks adoption and outcomes:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"did the agent follow the learning?"}),"\n",(0,a.jsx)(n.li,{children:"did reward scores improve?"}),"\n",(0,a.jsx)(n.li,{children:"did failures drop?"}),"\n"]}),(0,a.jsx)(n.p,{children:"If adoption is low or outcomes degrade, the learning is removed or demoted."})]}),"\n",(0,a.jsx)(n.h2,{id:"where-learnings-live",children:"Where Learnings Live"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsxs)(n.p,{children:["Learnings are stored per agent (using ",(0,a.jsx)(n.code,{children:"learning_key"}),", usually the ",(0,a.jsx)(n.code,{children:"agent_id"}),").\nThat means each agent has its own learning set."]}),(0,a.jsx)(n.p,{children:"In multi\u2011agent systems, each agent has separate learnings."})]}),"\n",(0,a.jsx)(n.h2,{id:"how-learnings-are-used",children:"How Learnings Are Used"}),"\n",(0,a.jsxs)("div",{className:"marlo-card",style:{border:"1px solid #E6E6E6",borderRadius:"12px",padding:"14px",backgroundColor:"#FFFFFF"},children:[(0,a.jsx)(n.p,{children:"The SDK returns learnings as text.\nYou inject them into your system prompt."}),(0,a.jsx)(n.p,{children:"Example:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'learnings_text = marlo.get_learnings_text()\n\nSYSTEM_PROMPT = f"""\nYou are a support agent.\n\nLearnings:\n{learnings_text}\n"""\n'})}),(0,a.jsx)(n.p,{children:"If you do not inject learnings, they exist but they do not affect the agent."})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>t,x:()=>o});var s=r(6540);const a={},i=s.createContext(a);function t(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);