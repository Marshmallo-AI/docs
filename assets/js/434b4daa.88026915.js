"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[176],{2354(e,t,n){n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"features/rewards","title":"How Rewards Work","description":"What the Judge Does","source":"@site/docs/features/rewards.md","sourceDirName":"features","slug":"/features/rewards","permalink":"/features/rewards","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/features/rewards.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Tracing","permalink":"/features/tracing"},"next":{"title":"How Learning Works","permalink":"/features/learning"}}');var r=n(4848),a=n(8453);const o={sidebar_position:2},i="How Rewards Work",d={},u=[{value:"What the Judge Does",id:"what-the-judge-does",level:2},{value:"Inputs and Outputs",id:"inputs-and-outputs",level:2},{value:"When Rewards Run",id:"when-rewards-run",level:2},{value:"Long Tasks (Memory)",id:"long-tasks-memory",level:2},{value:"Reasoning",id:"reasoning",level:2}];function l(e){const t={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"how-rewards-work",children:"How Rewards Work"})}),"\n",(0,r.jsx)(t.h2,{id:"what-the-judge-does",children:"What the Judge Does"}),"\n",(0,r.jsx)(t.p,{children:"The judge looks at one task at a time. It reads the task trajectory and the final answer, then returns a score and rationale."}),"\n",(0,r.jsx)(t.h2,{id:"inputs-and-outputs",children:"Inputs and Outputs"}),"\n",(0,r.jsx)(t.p,{children:"Inputs: task text, task events, final answer, and metadata.\nOutputs: score, principles, rationale, and uncertainty."}),"\n",(0,r.jsx)(t.p,{children:"If you use sub\u2011agents, the agent tree is included in the context."}),"\n",(0,r.jsx)(t.h2,{id:"when-rewards-run",children:"When Rewards Run"}),"\n",(0,r.jsx)(t.p,{children:"Rewards run after a task is finalized and you call the reward runner."}),"\n",(0,r.jsx)(t.h2,{id:"long-tasks-memory",children:"Long Tasks (Memory)"}),"\n",(0,r.jsx)(t.p,{children:"If a task is too large, Marlo summarizes the events into a memory state. The judge uses that summary instead of the full list."}),"\n",(0,r.jsx)(t.h2,{id:"reasoning",children:"Reasoning"}),"\n",(0,r.jsxs)(t.p,{children:["If your model returns reasoning, include it in ",(0,r.jsx)(t.code,{children:"track_llm"}),". The judge will use it when available."]})]})}function c(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453(e,t,n){n.d(t,{R:()=>o,x:()=>i});var s=n(6540);const r={},a=s.createContext(r);function o(e){const t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);